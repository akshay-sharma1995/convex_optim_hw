{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                                                                                                                                                                                                                          \n",
    "import matplotlib as mpl                                                                                                                                                                                                                                                    \n",
    "import matplotlib.pyplot as plt                                                                                                                                                                                                                                             \n",
    "import os                                                                                                                                                                                                                                                                   \n",
    "import argparse                                                                                                                                                                                                                                                             \n",
    "import pdb                                                                                                                                                                                                                                                                  \n",
    "import time                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():                                                                                                                                                                                                                                                           \n",
    "    parser = argparse.ArgumentParser()                                                                                                                                                                                                                                      \n",
    "                                                                                                                                                                                                                                                                            \n",
    "    parser.add_argument('--lr', dest='lr', type=float, default=1e-3, help=\"learning rate\")                                                                                                                                                                                  \n",
    "    parser.add_argument('--batch_size', dest='momentum', type=float, default=0.9, help=\"batch_size\")                                                                                                                                                                        \n",
    "                                                                                                                                                                                                                                                                            \n",
    "    return parser.parse_args()                                                                                                                                                                                                                                              \n",
    "                                                                                                                                                                                                                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_path=\"./\"):   \n",
    "    image_size = 28 # width and length of mnist image\n",
    "    num_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "    image_pixels = image_size * image_size\n",
    "    train_data = np.loadtxt(os.path.join(data_path,\"mnist_train.csv\"), delimiter=\",\")\n",
    "    test_data = np.loadtxt(os.path.join(data_path,\"mnist_train.csv\"), delimiter=\",\") \n",
    "    return {\"train_data\":train_data,\n",
    "            \"test_data\": test_data,\n",
    "           }\n",
    "\n",
    "                                                                                                                                                                                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(raw_data, labels_req=[0,1]):\n",
    "    train_data = raw_data[\"train_data\"]\n",
    "    test_data = raw_data[\"test_data\"]\n",
    "\n",
    "    # rescale image from 0-255 to 0-1\n",
    "    fac = 1.0 / 255\n",
    "    train_imgs = np.asfarray(train_data[:, 1:])\n",
    "    test_imgs = np.asfarray(test_data[:, 1:])\n",
    "    train_labels = np.asfarray(train_data[:, :1])\n",
    "    test_labels = np.asfarray(test_data[:, :1])\n",
    "    \n",
    "    train_imgs = np.divide(train_imgs, np.linalg.norm(train_imgs, axis=1, keepdims=True))\n",
    "    test_imgs = np.divide(test_imgs, np.linalg.norm(test_imgs, axis=1, keepdims=True))\n",
    "    \n",
    "    train_mask = np.isin(train_labels[:,0],labels_req)\n",
    "    test_mask = np.isin(test_labels[:,0],labels_req)\n",
    "    \n",
    "    dataset = { \"X_train\": train_imgs[train_mask],\n",
    "                \"Y_train\": train_labels[train_mask]*2.0 - 1.0,\n",
    "                \"X_test\": test_imgs[test_mask],\n",
    "                \"Y_test\": test_labels[test_mask]*2.0 - 1.0,\n",
    "            }\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_dataset(data_path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = process_data(raw_data.copy(),labels_req=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_props(data_arr,prop_names, figname, xlabel, x_data=None):                                                                                                                                                                                                                                             \n",
    "    fig = plt.figure(figsize=(16,9))  \n",
    "    \n",
    "    for i in range(len(data_arr)):\n",
    "        if(x_data):\n",
    "#             print(x_data.shape, data_arr.shape)\n",
    "            plt.plot(x_data[i], data_arr[i], label=prop_names[i])\n",
    "        else:\n",
    "            plt.plot(data_arr[i], label=prop_names[i])                                                                                                                                                                                                                                                          \n",
    "        plt.ylabel(\"train_losses\")\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.legend()\n",
    "    plt.title(figname)\n",
    "    plt.savefig(\"./{}.pdf\".format(figname))\n",
    "#     plt.show()\n",
    "                                                                                                                                                                                                                                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_grad(W, X, y_true, require_grad=True):\n",
    "    '''\n",
    "    W: weight vector (n,)\n",
    "    X: input batch (batch_size, n)\n",
    "    '''\n",
    "    dot_prod = np.matmul(X,W)\n",
    "    expo = np.exp(-np.multiply(y_true, dot_prod))\n",
    "    loss = np.mean(np.log(1 + expo))\n",
    "    if require_grad:\n",
    "        grad = np.divide(expo , (1+expo))\n",
    "        grad = np.multiply(grad, -1.0*np.multiply(y_true,X))\n",
    "        grad = np.mean(grad, 0)\n",
    "        return loss, grad\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_data(W, train_data, train_labels):\n",
    "    train_loss = get_loss_grad(W, train_data, train_labels, require_grad=False)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(lr,batch_size):                                                                                                                                                                                                                                                             \n",
    "    data_path = \"./\"                                                                                                                                                                                                                                                        \n",
    "    num_iters = 500                                                                                                                                                                                                                                                         \n",
    "    X_train, Y_train = dataset[\"X_train\"], dataset[\"Y_train\"]\n",
    "    X_test, Y_test = dataset[\"X_test\"], dataset[\"Y_test\"]\n",
    "    \n",
    "    in_dim = X_train.shape[1]\n",
    "    W = np.zeros(shape=(in_dim,1))\n",
    "    \n",
    "    train_data_loss_arr = []\n",
    "    train_time_arr = []\n",
    "    start_time = time.time()\n",
    "    eval_time = 0.\n",
    "    loss_calc_time = 0.\n",
    "    for i in range(num_iters): \n",
    "        train_data_loss = 0.0\n",
    "        idxs = np.random.choice(X_train.shape[0], batch_size, replace=True)        \n",
    "        X = X_train[idxs]\n",
    "        y_true = Y_train[idxs]\n",
    "        \n",
    "        loss, grad = get_loss_grad(W, X, y_true)\n",
    "        train_time_arr.append(time.time() - start_time - loss_calc_time)\n",
    "        \n",
    "        temp = time.time()\n",
    "        train_data_loss_arr.append(test_train_data(W, X_train, Y_train)*1.0)\n",
    "        loss_calc_time += time.time() - temp\n",
    "        W[:,0] -= lr*grad\n",
    "\n",
    "        \n",
    "        \n",
    "    return np.array(train_data_loss_arr), np.array(train_time_arr)\n",
    "    \n",
    "#     plot_props(train_data_loss_arr, \"train_data_loss_lr_{}_batch_size_{}\".format(lr, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [1.0,0.3,0.1,0.01]\n",
    "batch_sizes = [1,10,100]\n",
    "# lrs = [1.0]\n",
    "# batch_sizes = [10]\n",
    "TRAIN_LOSSES = []\n",
    "TRAIN_TIMES = []\n",
    "PROP_NAMES = []\n",
    "for batch_size in batch_sizes:\n",
    "    print(\"batch_size\", batch_size)\n",
    "    prop_names = []\n",
    "    train_losses = []\n",
    "    train_times = []\n",
    "    for lr in lrs:\n",
    "        print(\"learning_rate\", lr)\n",
    "        start_time = time.time()\n",
    "        train_loss, train_time = main(lr, batch_size)\n",
    "        train_losses.append(train_loss*1.0)\n",
    "        train_times.append(train_time*1.0)\n",
    "#         print(\"Time_taken: {:1f}\".format(time.time() - start_time))\n",
    "        prop_names.append(\"lr_{}_batch_size_{}\".format(lr, batch_size))\n",
    "    plot_props(train_losses, prop_names, \"loss_vs_epochs_batch_size_{}\".format(batch_size),\"epochs\")\n",
    "    plot_props(train_losses, prop_names, \"loss_vs_time_batch_size_{}\".format(batch_size), \"train_time\", train_times)\n",
    "    TRAIN_LOSSES.extend(train_losses)\n",
    "    TRAIN_TIMES.extend(train_times)\n",
    "    PROP_NAMES.extend(prop_names)\n",
    "plot_props(TRAIN_LOSSES, PROP_NAMES, \"loss_vs_epochs\", \"epochs\")\n",
    "plot_props(TRAIN_LOSSES, PROP_NAMES, \"loss_vs_time\", \"train_time\", TRAIN_TIMES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
